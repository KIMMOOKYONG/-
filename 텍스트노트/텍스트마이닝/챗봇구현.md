# 대화 모델 데이터 만들기
- 질문과 답변의 쌍을 가진 데이터 셋을 준비한다.
- 대화의 주제별로 데이터 셋을 구성하는것이 매우 중요하고
- 대화의 문맥을 관리할 수 있는 프로그래밍 적인 요소가 필요하다.
- 단답 처리에는 현재의 모델이 적합하나 긴 대화를 위해서는 문맥관리가 필수적이다.


# 모델 구현
```python
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

```

```python
model = SentenceTransformer("jhgan/ko-sroberta-multitask")

sentences = ["안녕하세요?", "한국어 문장 임베딩을 위한 버트 모델입니다."]
embeddings = model.encode(sentences)
print(embeddings)

```
![image](https://user-images.githubusercontent.com/102650331/170851430-c73ab81c-f1ee-40be-bc56-969bdd364563.png)

```python
df = pd.read_csv("https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv")
df.head()

```
![image](https://user-images.githubusercontent.com/102650331/170851443-29899633-0d16-40ca-be77-c3abb2d6ed49.png)

```python
# 사용자 입력
df.loc[0, "Q"]
model.encode(df.loc[0, "Q"])

# 답변 생성
df["embedding"] = pd.Series([[]] * len(df)) # dummy
df["embedding"] = df["Q"].map(lambda x: list(model.encode(x)))
df.head()

```
![image](https://user-images.githubusercontent.com/102650331/170851468-df36916a-d45a-4883-a19a-0162325774eb.png)

# 모델 테스트
```python
text = "날씨 죽이네"
embedding = model.encode(text)

df["distance"] = df["embedding"].map(lambda x: cosine_similarity([embedding], [x]).squeeze())
df.head()

```
![image](https://user-images.githubusercontent.com/102650331/170851543-6a47e6be-6ba8-448d-984a-b92575379aa4.png)

```python
answer = df.loc[df["distance"].idxmax()]

print("유사한 질문", answer["Q"])
print("챗봇 답변", answer["A"])
print("유사도", answer["distance"])

```
![image](https://user-images.githubusercontent.com/102650331/170851561-07a25e71-e7d2-4760-8afa-bc8d79fd4676.png)

# 모델 데이터 저장
```python
df.to_csv("chat_data.csv")

```
# 인터페이스 구현
```python
import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import json

@st.cache(allow_output_mutation=True)
def cached_model():
    model = SentenceTransformer("jhgan/ko-sroberta-multitask")
    return model

@st.cache(allow_output_mutation=True)
def get_dataset():
    df = pd.read_csv("chat_data.csv")
    df["embedding"] = df["embedding"].apply(json.loads)
    return df

model = cached_model()
df = get_dataset()

st.header("일상 대화 챗봇")

if "generated" not in st.session_state:
    st.session_state["generated"] = []

if "past" not in st.session_state:
    st.session_state["past"] = []

with st.form("form", clear_on_submit=True):
    user_input = st.text_input("당신: ", "")
    submitted = st.form_submit_button("전송")

if submitted and user_input:
    embedding = model.encode(user_input)

    df["distance"] = df["embedding"].map(lambda x: cosine_similarity([embedding], [x]).squeeze())
    answer = df.loc[df["distance"].idxmax()]

    st.session_state.past.append(user_input)
    st.session_state.generated.append(answer["A"])

message = st.empty()
for i in range(len(st.session_state["past"])):
    # message.text("당신: " + st.session_state["past"][i])
    if len(st.session_state["generated"]) > i:
        message.text("챗봇: " + st.session_state["generated"][i]) 

```
![image](https://user-images.githubusercontent.com/102650331/170852109-e63d20da-db2a-435a-bda0-984d872ea8e6.png)

